{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import IsolationForest\r\n",
    "import joblib\r\n",
    "\r\n",
    "time_freq = '15s'\r\n",
    "image_length = 40"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "# Functions Cell\r\n",
    "\r\n",
    "# Function to transform DataFrame from packets to packets per time_group variable.\r\n",
    "# Returns DataFrame with MAC addresses, average volumes, and average delta times \r\n",
    "# of packets every time_group \r\n",
    "# Input: DataFrame, string (MAC address)\r\n",
    "# Return DataFrame\r\n",
    "def transform(df, mac):\r\n",
    "    df['Epoch Time'] = pd.to_datetime(df['Epoch Time'], errors='coerce')\r\n",
    "    packets_per_min = df.set_index('Epoch Time').groupby(pd.Grouper(freq=time_freq))['Length'].mean()\r\n",
    "    packets_per_min = packets_per_min.fillna(0)\r\n",
    "\r\n",
    "    time_deltas = df.set_index('Epoch Time').groupby(pd.Grouper(freq=time_freq))['Delta Time'].mean()\r\n",
    "    time_deltas = time_deltas.fillna(time_deltas.mean())\r\n",
    "    df = pd.merge(packets_per_min, time_deltas, left_index=True, right_index=True)\r\n",
    "\r\n",
    "    df['MAC Source'] = mac\r\n",
    "    return df\r\n",
    "\r\n",
    "# Function to train and save an Isolation Forest model for a specific MAC address.\r\n",
    "# This model is used to return outliers for input time frequencies\r\n",
    "# Input: DataFrame, string (MAC address)\r\n",
    "# Return: void\r\n",
    "def train_and_save_S_model(df, mac):\r\n",
    "    #df = df[df['MAC Source']==mac]\r\n",
    "    # df = transform(df)\r\n",
    "\r\n",
    "    X = df[['Delta Time']].values\r\n",
    "    x_str = [str(i) for i in X]\r\n",
    "    clf = DecisionTreeClassifier().fit(np.array(X).reshape(-1,1), x_str)\r\n",
    "    \r\n",
    "    filename = '../models3'\r\n",
    "    joblib.dump(clf, filename + '\\\\' + mac.replace(':','') + '.sav')\r\n",
    "\r\n",
    "\r\n",
    "# Function that takes an IsolationForest model and an \"image,\" or time frequency, of data\r\n",
    "# and detects the outliers.\r\n",
    "# Input: DataFrame, model (IsolationForest)\r\n",
    "def detect_outliers(df, comparison_model):\r\n",
    "    X = df['Delta Time'].values\r\n",
    "    y_pred = model.predict(np.array(X).reshape(-1,1))\r\n",
    "    # print(y_pred)\r\n",
    "    y_pred = [float(i.strip('][')) for i in y_pred]\r\n",
    "\r\n",
    "    return y_pred # percentage of outliers\r\n",
    "\r\n",
    "\r\n",
    "# Function that takes two time interval images of data and an outlier model, returning the absolute\r\n",
    "# difference in outliers between the two.\r\n",
    "# Input: DataFrame (anchor image), DataFrame (test image), model (IsolationForest) \r\n",
    "def compare_models(df_1, df_2, outlier_model, label):\r\n",
    "\r\n",
    "    x = detect_outliers(df_1, outlier_model)\r\n",
    "    y = detect_outliers(df_2, outlier_model)\r\n",
    "    print(np.sum(abs(np.array(x)-np.array(y))), label)\r\n",
    "\r\n",
    "    return np.sum(abs(np.array(x)-np.array(y))) #((abs(percent_of_outliers_2 - percent_of_outliers_anchor))/percent_of_outliers_anchor)*100\r\n",
    "\r\n",
    "\r\n",
    "# Function to extract the time groups (images) of data from a given dataset (network traffic).\r\n",
    "# The input data should only be for one MAC, if not, it should be sorted where it can be grouped.\r\n",
    "# e.g. if time_freq = '15s' and image_length = 60, the time frame is 15 minutes of data per image.\r\n",
    "#\r\n",
    "# Input: DataFrame\r\n",
    "# Return: List of Dataframes \r\n",
    "def extract_images_and_labes(df):\r\n",
    "    df = pd.DataFrame(df)\r\n",
    "    df['Time'] = df.index\r\n",
    "    df.index = pd.RangeIndex(len(df.index))\r\n",
    "    groups = df.groupby([df.index // image_length])\r\n",
    "    \r\n",
    "    mac_images = []\r\n",
    "    mac_labels = []\r\n",
    "    for _, g in groups:\r\n",
    "\r\n",
    "        image = g[['Delta Time']]\r\n",
    "        rows_needed = image_length-len(image)\r\n",
    "        for _ in range(rows_needed):\r\n",
    "            image.loc[len(df.index)] = [image.mean()] \r\n",
    "        mac_images.append(image)\r\n",
    "        mac_labels.append(g['MAC Source'].unique()[0])\r\n",
    "    return mac_images, mac_labels\r\n",
    "\r\n",
    "# Function to transform data into time intervals, then return grouped time frequencies\r\n",
    "# and labels from the input DataFrame.\r\n",
    "# Input: DataFrame\r\n",
    "# Return: List of DataFrames, List of Strings\r\n",
    "def transform_data(df):\r\n",
    "    macs = ['00:0c:29:9d:9e:9e','00:80:f4:09:51:3b','48:5b:39:64:40:79','00:0c:29:e6:14:0d']\r\n",
    "    df = df[df['MAC Source'].isin(macs)]\r\n",
    "    grouped_mac = df.groupby(df['MAC Source'])\r\n",
    "    mac_arr_df = [grouped_mac.get_group(d) for d in df['MAC Source'].unique()]\r\n",
    "\r\n",
    "    images = []\r\n",
    "    labels = []\r\n",
    "    for df in mac_arr_df:\r\n",
    "        df['Epoch Time'] = pd.to_datetime(df['Epoch Time'], errors='coerce')\r\n",
    "        packets_per_min = df.set_index('Epoch Time').groupby(pd.Grouper(freq=time_freq))['No.'].count()\r\n",
    "        packets_per_min = packets_per_min.fillna(0)\r\n",
    "\r\n",
    "        time_deltas = df.set_index('Epoch Time').groupby(pd.Grouper(freq=time_freq))['Delta Time'].mean()\r\n",
    "        time_deltas = time_deltas.fillna(time_deltas.mean())\r\n",
    "        df_final = pd.merge(packets_per_min, time_deltas, left_index=True, right_index=True)\r\n",
    "\r\n",
    "        # Assigns the MAC address to the \r\n",
    "        df_final['MAC Source'] = df['MAC Source'].unique()[0]\r\n",
    "\r\n",
    "        df = df_final[:-1] # get rid of extra row at end\r\n",
    "        imgs, lbls = extract_images_and_labes(df_final)\r\n",
    "        images += imgs\r\n",
    "        labels += lbls\r\n",
    "\r\n",
    "    return images, labels\r\n",
    "\r\n",
    "\r\n",
    "# Function to create positive and negavite combinations of images for the \r\n",
    "# Desicion Tree model training phase. It takes both images and labels from specific MAC\r\n",
    "# and all MACs to create both the positive and negative image pairs. \r\n",
    "# The dimensions of the pairs is (len(images)*2, 2, image_length).\r\n",
    "# e.g. (90, 2, 60): 90 pairs, 2 columns (features), 60 rows\r\n",
    "#\r\n",
    "# len(images)*2: for each images a positive and negative match are generated, hence the times 2\r\n",
    "# 2: two columns for each feature - avg volume, avg time delta\r\n",
    "# image length: how many rows in the image (depending on the time groupings and frequency)\r\n",
    "# \r\n",
    "# Inupt: List of DataFrames, List of Strings, List of DataFrames, List of Strings\r\n",
    "# Return: List of Pair of Lists, List of Strings\r\n",
    "def make_pairs(images, labels, images_extra, labels_extra):\r\n",
    "    \r\n",
    "    pairImages = []\r\n",
    "    pairLabels = []\r\n",
    "\r\n",
    "    df = pd.DataFrame([i for i in range(len(images))], columns=['idx'])\r\n",
    "    df['label'] = labels\r\n",
    "\r\n",
    "    df_extra = pd.DataFrame([i for i in range(len(images_extra))], columns=['idx'])\r\n",
    "    df_extra['label'] = labels_extra\r\n",
    "\r\n",
    "    for idx, image in enumerate(images):\r\n",
    "        label = labels[idx]\r\n",
    "        \r\n",
    "        pos_df = df\r\n",
    "        pos_img_idx = pos_df.sample().to_numpy()[0][0]\r\n",
    "        pos_img = images[pos_img_idx]\r\n",
    "        pairImages.append((image, pos_img))\r\n",
    "        pairLabels.append(['Normal'])\r\n",
    "\r\n",
    "        neg_df = df_extra[df_extra['label'] != label]\r\n",
    "        neg_img_idx = neg_df.sample().to_numpy()[0][0]\r\n",
    "        neg_img = images_extra[neg_img_idx]\r\n",
    "        pairImages.append((image, neg_img))\r\n",
    "        pairLabels.append(['Rouge'])\r\n",
    "    \r\n",
    "    return (pairImages, pairLabels)\r\n",
    "\r\n",
    "# Function to train and save the comparison model. This takes the encodings (or absolute differences) \r\n",
    "# of two devices and the labels mapped to the encodings (whether or not the images match). The model\r\n",
    "# then trains and recognizes what device images match and which do not.\r\n",
    "# Input: List of ints, List of strings, string (MAC address)\r\n",
    "def train_and_save_C_model(encodings, labels, mac):\r\n",
    "    model = DecisionTreeClassifier()\r\n",
    "    model.fit(encodings, labels)\r\n",
    "\r\n",
    "    filename = '../models3' + mac.replace(':','') + '_compare.sav'\r\n",
    "    joblib.dump(model, filename)\r\n",
    "    return model\r\n",
    "    \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# Train and save the outlier models for each auth device\r\n",
    "\r\n",
    "data = '../../test_data/csv2/eth2dump-clean-6h_1.csv'\r\n",
    "df = pd.read_csv(data)\r\n",
    "df = df[(df['MAC Source']=='00:0c:29:e6:14:0d') | (df['MAC Source']=='00:0c:29:9d:9e:9e') | (df['MAC Source']=='48:5b:39:64:40:79') | (df['MAC Source']=='00:80:f4:09:51:3b')]\r\n",
    "\r\n",
    "grouped_ip = df.groupby(df['MAC Source'])\r\n",
    "macs_arr = [grouped_ip.get_group(d) for d in df['MAC Source'].unique()]\r\n",
    "# iterate through each mac/device\r\n",
    "for mac in macs_arr:\r\n",
    "    name = mac['MAC Source'].unique()[0]\r\n",
    "    df = transform(mac, name)\r\n",
    "    # save model\r\n",
    "    train_and_save_S_model(df, name)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# start to train the DT difference models for each auth device\r\n",
    "\r\n",
    "# iterate through clean data and compbine into one DataFrame, also grouping the data by time frequency declared by time_freq\r\n",
    "import glob\r\n",
    "dfs = []\r\n",
    "files = glob.glob('../../test_data/csv2/*.csv')\r\n",
    "for file in files[0:3]:\r\n",
    "    print(file)\r\n",
    "    macs = ['00:0c:29:9d:9e:9e','00:80:f4:09:51:3b','48:5b:39:64:40:79','00:0c:29:e6:14:0d']\r\n",
    "    df = pd.read_csv(file)\r\n",
    "    df = df[df['MAC Source'].isin(macs)]\r\n",
    "    grouped_ip = df.groupby(df['MAC Source'])\r\n",
    "    macs_arr = [grouped_ip.get_group(d) for d in df['MAC Source'].unique()]\r\n",
    "    macs = []\r\n",
    "    for mac in macs_arr:\r\n",
    "        label = mac['MAC Source'].unique()[0]\r\n",
    "        mac = transform(mac, label)\r\n",
    "        macs.append(mac[:-1])\r\n",
    "    df = pd.concat(macs)\r\n",
    "    dfs.append(df)\r\n",
    "df = pd.concat(dfs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C:\\Users\\carlo\\Documents\\College\\reu_cyber\\test_data\\csv2\\eth2dump-clean-0,5h_1.csv\n",
      "C:\\Users\\carlo\\Documents\\College\\reu_cyber\\test_data\\csv2\\eth2dump-clean-1h_1.csv\n",
      "C:\\Users\\carlo\\Documents\\College\\reu_cyber\\test_data\\csv2\\eth2dump-clean-6h_1.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# extract all time frame images for negative matches used later\r\n",
    "all_images, all_labels = extract_images_and_labes(df)\r\n",
    "len(all_images)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "# group clean data by MAC address\r\n",
    "grouped_ip = df.groupby(df['MAC Source'])\r\n",
    "macs_arr = [grouped_ip.get_group(d) for d in df['MAC Source'].unique()]\r\n",
    "\r\n",
    "# EXPLAINATION:\r\n",
    "\r\n",
    "# iterate through MACs \r\n",
    "# for each mac: \r\n",
    "#   get its time interval images \r\n",
    "#   get both positive and negative matches for training, as well as the labels indicating their relationship\r\n",
    "#   for each pair/match:\r\n",
    "#       get absolute difference between the two\r\n",
    "#   train the DT on the absolute difference encodins (similarity score) and their labels (match or not)\r\n",
    "\r\n",
    "# models should now know which image differences are similar and declared positive, or vice verse \r\n",
    "\r\n",
    "\r\n",
    "for mac_df in macs_arr:\r\n",
    "    mac_label = mac_df['MAC Source'].unique()[0]\r\n",
    "    print('mac_df =',mac_label)\r\n",
    "    mac_images, mac_labels = extract_images_and_labes(mac_df)\r\n",
    "    \r\n",
    "    pairs, labels = make_pairs(mac_images, mac_labels, all_images, all_labels)\r\n",
    "    \r\n",
    "    filename = '../models3'\r\n",
    "    model = joblib.load(filename + '\\\\' + mac_label.replace(':','') + '.sav')\r\n",
    "\r\n",
    "    encodings = []\r\n",
    "    labels_return = []\r\n",
    "    for pair, label in zip(pairs,labels):\r\n",
    "        # print(np.array(pair[0]).shape, np.array(pair[1]).shape)\r\n",
    "        result = [compare_models(pair[0], pair[1], model, label[0])]\r\n",
    "        encodings.append(result)\r\n",
    "        labels_return.append(label[0])\r\n",
    "    model = train_and_save_C_model(encodings, labels_return, mac_label)\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mac_df = 00:0c:29:9d:9e:9e\n",
      "0.22870738000000013 Normal\n",
      "2.1108565599999998 Rouge\n",
      "0.22363688000000007 Normal\n",
      "2.04174958 Rouge\n",
      "0.17907486000000006 Normal\n",
      "2.1365554399999995 Rouge\n",
      "0.22177024999999997 Normal\n",
      "1.8906531899999999 Rouge\n",
      "0.17792994000000012 Normal\n",
      "1.9683429899999998 Rouge\n",
      "0.18545605999999998 Normal\n",
      "2.0060359199999995 Rouge\n",
      "0.15881212999999997 Normal\n",
      "1.9861269499999996 Rouge\n",
      "0.3052638700000001 Normal\n",
      "1.9526881099999998 Rouge\n",
      "0.16428498999999996 Normal\n",
      "1.9956478599999998 Rouge\n",
      "0.14157820999999998 Normal\n",
      "2.05232479 Rouge\n",
      "0.16999951 Normal\n",
      "2.0122746299999994 Rouge\n",
      "0.20952981999999998 Normal\n",
      "2.1095672599999995 Rouge\n",
      "0.16543991999999996 Normal\n",
      "2.07395936 Rouge\n",
      "0.19325257999999998 Normal\n",
      "1.9177359699999998 Rouge\n",
      "0.1705362700000001 Normal\n",
      "2.06094492 Rouge\n",
      "0.19901367000000003 Normal\n",
      "2.0587464699999996 Rouge\n",
      "0.22320378999999985 Normal\n",
      "2.0106440599999997 Rouge\n",
      "0.24248627 Normal\n",
      "2.04584653 Rouge\n",
      "0.23261166000000005 Normal\n",
      "2.0720304799999996 Rouge\n",
      "0.2991552200000001 Normal\n",
      "1.9587631599999997 Rouge\n",
      "0.1186192400000001 Normal\n",
      "2.0547327799999997 Rouge\n",
      "0.19539465 Normal\n",
      "2.0566636999999997 Rouge\n",
      "0.17862572999999998 Normal\n",
      "2.0138648099999994 Rouge\n",
      "0.19334411000000007 Normal\n",
      "1.9855435999999997 Rouge\n",
      "0.0 Normal\n",
      "1.9841161599999997 Rouge\n",
      "0.15020567 Normal\n",
      "1.94132523 Rouge\n",
      "0.2320461800000001 Normal\n",
      "1.9218093099999998 Rouge\n",
      "0.14957011 Normal\n",
      "1.9911944699999995 Rouge\n",
      "0.21492321 Normal\n",
      "1.9956548099999998 Rouge\n",
      "0.17158805999999993 Normal\n",
      "1.9543138999999998 Rouge\n",
      "0.1662248 Normal\n",
      "1.9955884599999998 Rouge\n",
      "0.17949176000000006 Normal\n",
      "1.9545556999999998 Rouge\n",
      "0.21121533999999997 Normal\n",
      "1.9380381999999998 Rouge\n",
      "0.18805034000000004 Normal\n",
      "1.9692759499999997 Rouge\n",
      "0.15513563000000002 Normal\n",
      "1.9912609599999997 Rouge\n",
      "0.20939700999999994 Normal\n",
      "1.9270448399999998 Rouge\n",
      "0.16032606 Normal\n",
      "1.9488267799999996 Rouge\n",
      "0.1619778 Normal\n",
      "1.97356116 Rouge\n",
      "0.30518376999999997 Normal\n",
      "1.9265980899999997 Rouge\n",
      "0.21526599000000007 Normal\n",
      "1.9962195299999999 Rouge\n",
      "0.13778342000000007 Normal\n",
      "1.9989327999999995 Rouge\n",
      "0.21341888000000006 Normal\n",
      "1.9322129999999997 Rouge\n",
      "0.13409440000000006 Normal\n",
      "1.9968443899999997 Rouge\n",
      "0.14568091000000008 Normal\n",
      "2.0532295799999996 Rouge\n",
      "0.2212295900000001 Normal\n",
      "2.0021226 Rouge\n",
      "mac_df = 00:80:f4:09:51:3b\n",
      "0.012766060000000001 Normal\n",
      "0.09251281999999998 Rouge\n",
      "0.019456629999999996 Normal\n",
      "0.09127082 Rouge\n",
      "0.01593372 Normal\n",
      "0.09240867 Rouge\n",
      "0.02516121 Normal\n",
      "0.09032482 Rouge\n",
      "0.01161748 Normal\n",
      "0.09209734 Rouge\n",
      "0.018338 Normal\n",
      "0.09271707999999998 Rouge\n",
      "0.014597160000000001 Normal\n",
      "0.09462330999999999 Rouge\n",
      "0.015624969999999998 Normal\n",
      "0.09249231 Rouge\n",
      "0.02202233 Normal\n",
      "0.09356796999999999 Rouge\n",
      "0.0137189 Normal\n",
      "0.09193385999999999 Rouge\n",
      "0.014139959999999997 Normal\n",
      "0.08980364999999998 Rouge\n",
      "0.0134021 Normal\n",
      "0.09382004 Rouge\n",
      "0.012085759999999997 Normal\n",
      "0.09365185999999998 Rouge\n",
      "0.02208358 Normal\n",
      "0.09516779 Rouge\n",
      "0.013866820000000002 Normal\n",
      "0.09536718999999999 Rouge\n",
      "0.015811769999999996 Normal\n",
      "0.09464455 Rouge\n",
      "0.015252519999999999 Normal\n",
      "0.09111984 Rouge\n",
      "0.015130910000000006 Normal\n",
      "0.09122981999999999 Rouge\n",
      "0.018773400000000003 Normal\n",
      "0.08996076 Rouge\n",
      "0.022030129999999995 Normal\n",
      "0.09786368 Rouge\n",
      "0.014465339999999998 Normal\n",
      "0.09135294999999999 Rouge\n",
      "0.014014140000000001 Normal\n",
      "0.09454738999999998 Rouge\n",
      "0.01906225 Normal\n",
      "0.08869633999999998 Rouge\n",
      "0.018793909999999997 Normal\n",
      "0.09426353999999998 Rouge\n",
      "0.01397141 Normal\n",
      "0.09271680999999998 Rouge\n",
      "0.015478719999999998 Normal\n",
      "0.08994112 Rouge\n",
      "0.011348789999999997 Normal\n",
      "0.09262039 Rouge\n",
      "0.011538449999999999 Normal\n",
      "0.09288253999999999 Rouge\n",
      "0.01322655 Normal\n",
      "0.09425375 Rouge\n",
      "0.01946841 Normal\n",
      "0.09276611999999998 Rouge\n",
      "0.016945309999999998 Normal\n",
      "0.09339060999999999 Rouge\n",
      "0.017203579999999996 Normal\n",
      "0.09259053 Rouge\n",
      "0.018090060000000005 Normal\n",
      "0.08596037 Rouge\n",
      "0.01677719 Normal\n",
      "0.08979606999999999 Rouge\n",
      "0.01658204 Normal\n",
      "0.08694124999999998 Rouge\n",
      "0.0228655 Normal\n",
      "0.08830602 Rouge\n",
      "0.01612086 Normal\n",
      "0.09033211 Rouge\n",
      "0.020588839999999997 Normal\n",
      "0.08567602999999999 Rouge\n",
      "0.018836899999999997 Normal\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (40,) (38,) ",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-78278681339f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# print(np.array(pair[0]).shape, np.array(pair[1]).shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcompare_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mencodings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mlabels_return\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-99-8e00d2c2906f>\u001b[0m in \u001b[0;36mcompare_models\u001b[1;34m(df_1, df_2, outlier_model, label)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_outliers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutlier_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_outliers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutlier_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#((abs(percent_of_outliers_2 - percent_of_outliers_anchor))/percent_of_outliers_anchor)*100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (40,) (38,) "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6rc1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6rc1 64-bit"
  },
  "interpreter": {
   "hash": "24b480431558bd6270bf8e2dc4c7080d28b8c31c934dd629022acb274fa9e3cd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}