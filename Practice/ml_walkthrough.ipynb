{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6rc1 64-bit"
  },
  "interpreter": {
   "hash": "24b480431558bd6270bf8e2dc4c7080d28b8c31c934dd629022acb274fa9e3cd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn import datasets\r\n",
    "import pandas as pd\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn import metrics, preprocessing\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dataset = pd.read_csv ('test_iot1.csv')\r\n",
    "df = dataset.drop(columns =['Epoch Time', 'Time', 'Source', 'Destination'])\r\n",
    "le = preprocessing.LabelEncoder()\r\n",
    "strings_only = df.select_dtypes(include=[object])\r\n",
    "len(df)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1921098"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# df_transformed = strings_only.apply(le.fit_transform)\r\n",
    "# enc = preprocessing.OneHotEncoder()\r\n",
    "# enc.fit(df_transformed)\r\n",
    "for col in strings_only:\r\n",
    "    strings_only[col+' Num'] = [hash(val) for val in strings_only[col]]\r\n",
    "df_2 = df.drop(columns =['MAC Destination', 'Protocol', 'Info'])\r\n",
    "# df_3 = df_transformed.iloc[: , 1:]\r\n",
    "df_3 = strings_only.iloc[: , 5:]\r\n",
    "df = pd.merge(df_2, df_3, left_index=True, right_index=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-3-618fc6e49d9a>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  strings_only[col+' Num'] = [hash(val) for val in strings_only[col]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df['Source Port'] = df['Source Port'].fillna(0)\r\n",
    "df['Destination Port'] = df['Destination Port'].fillna(0)\r\n",
    "df = df.dropna()\r\n",
    "\r\n",
    "#len(df['No.'])\r\n",
    "for col in df:\r\n",
    "    print(col, len(df[col]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No. 1921093\n",
      "MAC Source 1921093\n",
      "Length 1921093\n",
      "Source Port 1921093\n",
      "Destination Port 1921093\n",
      "Delta Time 1921093\n",
      "MAC Destination Num 1921093\n",
      "Protocol Num 1921093\n",
      "Info Num 1921093\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "per_of_rows = 0.25\r\n",
    "rows = int(len(df)*per_of_rows)\r\n",
    "df = df[:rows]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X = df[['Length', 'Delta Time', 'Source Port', 'Destination Port', 'Info Num', 'Protocol Num', 'MAC Destination Num']]\r\n",
    "#dataset[['Source','MAC Destination','Destination','Length','Source Port','Destination Port','Protocol', 'Delta Time']]\r\n",
    "y = df['MAC Source']\r\n",
    "\r\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\r\n",
    "\r\n",
    "# #Create a Gaussian Classifier\r\n",
    "# clf=RandomForestClassifier(n_estimators=100)\r\n",
    "\r\n",
    "# #Train the model using the training sets y_pred=clf.predict(X_test)\r\n",
    "# clf.fit(X_train,y_train)\r\n",
    "\r\n",
    "# y_pred=clf.predict(X_test)\r\n",
    "# print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Import required libraries for performance metrics\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "import time\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from xgboost import XGBClassifier\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\r\n",
    "\r\n",
    "knn = KNeighborsClassifier()\r\n",
    "dtr = DecisionTreeClassifier(random_state=24)\r\n",
    "rfc = RandomForestClassifier(random_state=24)\r\n",
    "xboost= XGBClassifier(random_state=24)\r\n",
    "gnb = GaussianNB()\r\n",
    "\r\n",
    "models = [knn, dtr, rfc, xboost, gnb]\r\n",
    "models_scores_table = pd.DataFrame(index=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Time'])\r\n",
    "\r\n",
    "for model in models:\r\n",
    "    start = time.perf_counter()\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    y_pred= model.predict(X_test)\r\n",
    "    scores = [\r\n",
    "                accuracy_score(y_test, y_pred),\r\n",
    "                precision_score(y_test, y_pred,average='weighted'),\r\n",
    "                recall_score(y_test, y_pred,average='weighted'),\r\n",
    "                f1_score(y_test, y_pred,average='weighted')\r\n",
    "             ]\r\n",
    "    delta = time.perf_counter() - start\r\n",
    "    scores.append(delta)\r\n",
    "    models_scores_table[type(model).__name__] = scores\r\n",
    "    print(type(model).__name__, delta)\r\n",
    "\r\n",
    "# Add 'Best Score' column\r\n",
    "models_scores_table['Best Score'] = np.where(models_scores_table.index != 'Time', models_scores_table.idxmax(axis=1), models_scores_table.idxmin(axis=1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\carlo\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "KNeighborsClassifier 49.008616999999504\n",
      "DecisionTreeClassifier 4.217784299999039\n",
      "RandomForestClassifier 38.09459969999989\n",
      "C:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[15:24:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier 239.45642510000107\n",
      "C:\\Users\\carlo\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "GaussianNB 3.3859056000001146\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# models_scores_table.to_csv('results.csv')\r\n",
    "models_scores_table"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           KNeighborsClassifier  DecisionTreeClassifier  \\\n",
       "Accuracy               0.826592                0.981635   \n",
       "Precision              0.826824                0.981672   \n",
       "Recall                 0.826592                0.981635   \n",
       "F1 Score               0.824066                0.981650   \n",
       "Time                  49.008617                4.217784   \n",
       "\n",
       "           RandomForestClassifier  XGBClassifier  GaussianNB     Best Score  \n",
       "Accuracy                 0.983468       0.987264    0.554247  XGBClassifier  \n",
       "Precision                0.983353       0.987276    0.516756  XGBClassifier  \n",
       "Recall                   0.983468       0.987264    0.554247  XGBClassifier  \n",
       "F1 Score                 0.983293       0.987128    0.512725  XGBClassifier  \n",
       "Time                    38.094600     239.456425    3.385906     GaussianNB  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Best Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.826592</td>\n",
       "      <td>0.981635</td>\n",
       "      <td>0.983468</td>\n",
       "      <td>0.987264</td>\n",
       "      <td>0.554247</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.826824</td>\n",
       "      <td>0.981672</td>\n",
       "      <td>0.983353</td>\n",
       "      <td>0.987276</td>\n",
       "      <td>0.516756</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.826592</td>\n",
       "      <td>0.981635</td>\n",
       "      <td>0.983468</td>\n",
       "      <td>0.987264</td>\n",
       "      <td>0.554247</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.824066</td>\n",
       "      <td>0.981650</td>\n",
       "      <td>0.983293</td>\n",
       "      <td>0.987128</td>\n",
       "      <td>0.512725</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>49.008617</td>\n",
       "      <td>4.217784</td>\n",
       "      <td>38.094600</td>\n",
       "      <td>239.456425</td>\n",
       "      <td>3.385906</td>\n",
       "      <td>GaussianNB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "source": [
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.ensemble import IsolationForest\r\n",
    "\r\n",
    "df = dataset[dataset['MAC Source']=='00:0c:29:9d:9e:9e']\r\n",
    "df['Epoch Time'] = pd.to_datetime(df['Epoch Time'], errors='coerce')\r\n",
    "packets_per_sec = df.set_index('Epoch Time').groupby(pd.Grouper(freq='1min'))['Delta Time'].mean()\r\n",
    "df_small_noise = packets_per_sec[:-1].to_frame().reset_index()\r\n",
    "df_clean = df_small_noise.fillna(df_small_noise.mean())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-818-af6817c5455c>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Epoch Time'] = pd.to_datetime(df['Epoch Time'], errors='coerce')\n",
      "<ipython-input-818-af6817c5455c>:9: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_clean = df_small_noise.fillna(df_small_noise.mean())\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "source": [
    "model=IsolationForest(n_estimators=10, max_samples='auto', contamination=float(0.1),max_features=1.0)\r\n",
    "model.fit(df_clean[['Delta Time']])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "IsolationForest(contamination=0.1, n_estimators=10)"
      ]
     },
     "metadata": {},
     "execution_count": 819
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "source": [
    "# # i = 11\r\n",
    "# while True:\r\n",
    "#     if -1 not in model.predict(df_clean[['Delta Time']]): break\r\n",
    "#     # # model.set_params(n_estimators=i)\r\n",
    "#     df_clean['scores']=model.decision_function(df_clean[['Delta Time']])\r\n",
    "#     df_clean['anomaly']=model.predict(df_clean[['Delta Time']])\r\n",
    "#     anomaly=df_clean.loc[df_clean['anomaly']==-1]\r\n",
    "#     anomaly = anomaly.fillna(anomaly.mean())\r\n",
    "#     model.fit(anomaly[['Delta Time']])\r\n",
    "#     # print(len(anomaly))\r\n",
    "#     #print('yeet')\r\n",
    "# #anomaly.empty\r\n",
    "# # model.fit(anomaly[['Delta Time']])\r\n",
    "\r\n",
    "df_clean['scores']=model.decision_function(df_clean[['Delta Time']])\r\n",
    "df_clean['anomaly']=model.predict(df_clean[['Delta Time']])\r\n",
    "anomaly=df_clean.loc[df_clean['anomaly']==-1]\r\n",
    "anomaly = anomaly.fillna(anomaly.mean())\r\n",
    "# if len(anomaly) == 1:\r\n",
    "#     anomaly = anomaly.append(anomaly)\r\n",
    "model.fit(anomaly[['Delta Time']])\r\n",
    "len(anomaly)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-821-ce7d1882f83f>:18: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  anomaly = anomaly.fillna(anomaly.mean())\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 821
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "source": [
    "# df_clean.fillna(anomaly.mean())\r\n",
    "# df_clean['scores']=model.decision_function(df_clean[['Delta Time']])\r\n",
    "#df_clean['anomaly']=model.predict(df_clean[['Delta Time']])\r\n",
    "#anomaly=df_clean.loc[df_clean['anomaly']==-1]\r\n",
    "#anomaly"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "source": [
    "df_mitm = pd.read_csv ('test2.csv')\r\n",
    "df_mitm = df_mitm[df_mitm['MAC Source']=='00:0c:29:9d:9e:9e']\r\n",
    "df_mitm['Epoch Time'] = pd.to_datetime(df_mitm['Epoch Time'], errors='coerce')\r\n",
    "df_mitm = df_mitm.set_index('Epoch Time').groupby(pd.Grouper(freq='1min'))['Delta Time'].mean()\r\n",
    "df_mitm = df_mitm[:-1].to_frame().reset_index().fillna(df_mitm.mean())\r\n",
    "\r\n",
    "df_mitm['scores']=model.decision_function(df_mitm[['Delta Time']])\r\n",
    "df_mitm['anomaly']=model.predict(df_mitm[['Delta Time']])\r\n",
    "anomaly=df_mitm.loc[df_mitm['anomaly']==-1]\r\n",
    "anomaly\r\n",
    "\r\n",
    "# # threshold\r\n",
    "# threshold_score = anomaly['scores'].mean()\r\n",
    "\r\n",
    "# #anomalies\r\n",
    "# anomaly_final = anomaly[anomaly['scores'] < threshold_score]\r\n",
    "# anomaly_final "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Epoch Time, Delta Time, scores, anomaly]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch Time</th>\n",
       "      <th>Delta Time</th>\n",
       "      <th>scores</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 836
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}